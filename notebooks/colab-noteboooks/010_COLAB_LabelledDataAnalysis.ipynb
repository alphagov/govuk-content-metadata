{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# COLAB_LabelledDataAnalysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook to prepare the labelled token dataset for HuggingFace."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install transformers\n",
    "# !pip install s3fs\n",
    "# !pip install boto3\n",
    "# !pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import sagemaker\n",
    "import transformers\n",
    "from datasets import Dataset, load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"COLAB\"  # [\"AWS\", \"COLAB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if system == \"AWS\":\n",
    "    fs = s3fs.S3FileSystem()\n",
    "    s3_bucket = \"govuk-data-infrastructure-integration\"\n",
    "    DATA_DIR = f\"s3://{s3_bucket}/model-data/govner-data\"\n",
    "    for f in fs.ls(DATA_DIR):\n",
    "        print(f)\n",
    "    # Manage interactions with the Amazon SageMaker APIs and any other AWS services needed.\n",
    "    # sagemaker session bucket -> used for uploading data, models and logs\n",
    "    # sagemaker will automatically create this bucket if it not exists\n",
    "    sess = sagemaker.Session()\n",
    "    sagemaker_session_bucket = s3_bucket\n",
    "    if sagemaker_session_bucket is None and sess is not None:\n",
    "        # set to default bucket if a bucket name is not given\n",
    "        sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "    role = sagemaker.get_execution_role()\n",
    "    sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "    print(f\"sagemaker role arn: {role}\")\n",
    "    print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "    print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "elif system == \"COLAB\":\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    # DATA_DIR = os.path.join(\"/content/gdrive/My Drive\", \"NER/Data\")\n",
    "    DATA_DIR = os.path.join(\n",
    "        \"/content/gdrive/Shareddrives/\",\n",
    "        \"GOV.UK teams/2020-2021/Data labs/content-metadata-2021/Data\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 key prefix for the data\n",
    "dataset_name = \"line_by_line_NER_data_combined.csv\"\n",
    "\n",
    "dataset_path = f\"{DATA_DIR}/{dataset_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(dataset_path, sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literal eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"text_token\", \"labels\", \"label_list\"]:\n",
    "    df[i] = df[i].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[\"text_token\"][0])\n",
    "print(df[\"text_token\"][0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelled Counts\n",
    "\n",
    "Now, get the labelled counts for each row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f\"{DATA_DIR}/new_label_map.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "label_map = data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(label_map.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_labs = [\"O\", \"O\", \"FINANCE\", \"PERSON\", \"O\", \"O\", \"FINANCE\", \"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mini = df.head(5)\n",
    "df_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "df_mini[\"label_list_enc\"] = df_mini[\"label_list\"]\n",
    "df_mini = df_mini.join(\n",
    "    pd.DataFrame(\n",
    "        mlb.fit_transform(df_mini.pop(\"label_list_enc\")),\n",
    "        columns=mlb.classes_,\n",
    "        index=df_mini.index,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df_mini)):\n",
    "    print(df_mini[\"label_list\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def occurence_flag(df, column):\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    df_copy = df\n",
    "    df_copy[f\"{column}_cop\"] = df_copy[f\"{column}\"]\n",
    "    df_copy = df_copy.join(\n",
    "        pd.DataFrame(\n",
    "            mlb.fit_transform(df_copy.pop(f\"{column}_cop\")),\n",
    "            columns=mlb.classes_,\n",
    "            index=df_copy.index,\n",
    "        )\n",
    "    )\n",
    "    return df_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts = occurence_flag(df_mini, column=\"label_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply to full dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts = occurence_flag(df, column=\"label_list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = pd.DataFrame()\n",
    "for l in labels:\n",
    "    print(l)\n",
    "    new_df = df_counts[df_counts[l] == 1]\n",
    "    new_df = new_df.sample(2000)\n",
    "    new_df[\"sample\"] = l\n",
    "    main_df = main_df.append(new_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df[\"zip_tok_ent\"] = main_df.apply(\n",
    "    lambda x: list(zip(x.text_token, x.label_list)), axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df = main_df.reset_index()\n",
    "main_df = main_df.drop([\"index\"], axis=1)\n",
    "main_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df[\"zip_tok_ent\"][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_df.to_excel(f\"{DATA_DIR}/NER_data_combined_BREAKDOWN.xlsx\", index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
