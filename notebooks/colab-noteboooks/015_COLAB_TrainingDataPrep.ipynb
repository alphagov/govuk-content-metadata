{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 015_COLAB_JanuaryTrainingDataPrep\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a notebook to prepare the datasets for the training jobs run in January 2022 for project playback."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install datasets transformers torch seqeval &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from ast import literal_eval\n",
    "from collections import Counter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import transformers\n",
    "from datasets import Dataset, load_dataset, load_from_disk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"COLAB\"  # [\"AWS\", \"COLAB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if system == \"COLAB\":\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    # DATA_DIR = os.path.join(\"/content/gdrive/Shareddrives/\", \"GOV.UK teams/2020-2021/Data labs/content-metadata-2021/Data/Jan2022-Data\")\n",
    "    DATA_DIR = \"/content/gdrive/Shareddrives/GOV.UK teams/2020-2021/Data labs/content-metadata-2021/Data/Feb2022-Data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Load Datasets\n",
    "\n",
    "* The combined dataset (~230,000)\n",
    "* The validated dataset (~5,500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3_. HF Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_hf = load_from_disk(\n",
    "    \"/content/gdrive/Shareddrives/GOV.UK teams/2020-2021/Data labs/content-metadata-2021/Data/validated_ner_hf\"\n",
    ")\n",
    "unvalidated_hf = load_from_disk(\n",
    "    \"/content/gdrive/Shareddrives/GOV.UK teams/2020-2021/Data labs/content-metadata-2021/Data/hf_govuk_data\"\n",
    ")\n",
    "samp_unvalidated_hf = load_from_disk(\n",
    "    \"/content/gdrive/Shareddrives/GOV.UK teams/2020-2021/Data labs/content-metadata-2021/Data/samp_hf_govuk_data\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in validated_hf[\"train\"][0]:\n",
    "    print(validated_hf[\"train\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unvalidated_hf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in unvalidated_hf[\"train\"][0]:\n",
    "    print(unvalidated_hf[\"train\"][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_unvalidated_hf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3A. Validated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 key prefix for the data\n",
    "validated = \"govuk-labelled-data-ner-validated.csv\"\n",
    "validated_path = f\"{DATA_DIR}/{validated}\"\n",
    "validated_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_df = pd.read_csv(validated_path, sep=\",\")\n",
    "print(validated_df.shape)\n",
    "validated_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literal eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"labels\", \"labelled_entities\", \"label_list\", \"text_tokens\"]:\n",
    "    validated_df[i] = validated_df[i].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_df = validated_df[~validated_df.text.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_df = validated_df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_df = validated_df.reset_index()\n",
    "validated_df = validated_df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_labelmap = {\n",
    "    \"O\": 0,\n",
    "    \"I-CONTACT\": 1,\n",
    "    \"I-DATE\": 2,\n",
    "    \"I-EVENT\": 3,\n",
    "    \"I-FINANCE\": 4,\n",
    "    \"I-FORM\": 5,\n",
    "    \"I-LOCATION\": 6,\n",
    "    \"I-MISC\": 7,\n",
    "    \"I-MONEY\": 8,\n",
    "    \"I-ORGANIZATION\": 9,\n",
    "    \"I-PERSON\": 10,\n",
    "    \"I-SCHEME\": 11,\n",
    "    \"I-STATE\": 12,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def list_map_func(listy, mapping):\n",
    "    new_list = []\n",
    "    for i in listy:\n",
    "        new_list.append(mapping[i])\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_df[\"new_label_list_id\"] = validated_df[\"label_list\"].apply(\n",
    "    lambda x: list_map_func(x, validated_labelmap)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Individual**:\n",
    "\n",
    "O                 101033\n",
    "\n",
    "I-ORGANIZATION      5503\n",
    "\n",
    "I-FINANCE           4409\n",
    "\n",
    "I-PERSON            3410\n",
    "\n",
    "I-FORM              2715\n",
    "\n",
    "I-EVENT             2267\n",
    "\n",
    "I-DATE              1945\n",
    "\n",
    "I-STATE             1482\n",
    "\n",
    "I-LOCATION          1431\n",
    "\n",
    "I-MISC              1064\n",
    "\n",
    "I-CONTACT            987\n",
    "\n",
    "\n",
    "**Multi-word**\n",
    "\n",
    "ORGANIZATION    3096\n",
    "\n",
    "PERSON          2883\n",
    "\n",
    "FINANCE         2648\n",
    "\n",
    "FORM            1366\n",
    "\n",
    "EVENT           1324\n",
    "\n",
    "LOCATION        1029\n",
    "\n",
    "DATE             791\n",
    "\n",
    "CONTACT          669\n",
    "\n",
    "STATE            663\n",
    "\n",
    "MISC             503"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 20% of the validated data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_train, validated_test = train_test_split(\n",
    "    validated_df, test_size=0.2, random_state=43\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlb = MultiLabelBinarizer()\n",
    "validated_test_counts = validated_test.copy()\n",
    "validated_test_counts[\"label_list_enc\"] = validated_test_counts[\"label_list\"]\n",
    "validated_test_counts = validated_test_counts.join(\n",
    "    pd.DataFrame(\n",
    "        mlb.fit_transform(validated_test_counts.pop(\"label_list_enc\")),\n",
    "        columns=mlb.classes_,\n",
    "        index=validated_test_counts.index,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_test_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\n",
    "    \"I-CONTACT\",\n",
    "    \"I-DATE\",\n",
    "    \"I-EVENT\",\n",
    "    \"I-FINANCE\",\n",
    "    \"I-FORM\",\n",
    "    \"I-LOCATION\",\n",
    "    \"I-MISC\",\n",
    "    \"I-ORGANIZATION\",\n",
    "    \"I-PERSON\",\n",
    "    \"I-STATE\",\n",
    "    \"O\",\n",
    "]:\n",
    "    print(i, validated_test_counts[i].sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3B. Unvalidated Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 key prefix for the data\n",
    "unvalidated = \"govuk-labelled-data-ner.csv\"\n",
    "unvalidated_path = f\"{DATA_DIR}/{unvalidated}\"\n",
    "unvalidated_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unvalidated_df = pd.read_csv(unvalidated_path, sep=\",\")\n",
    "print(unvalidated_df.shape)\n",
    "unvalidated_df = unvalidated_df[\n",
    "    [\"text\", \"text_token\", \"labels\", \"label_list\", \"new_label_list_id\"]\n",
    "]\n",
    "unvalidated_df = unvalidated_df.rename(columns={\"text_token\": \"text_tokens\"})\n",
    "unvalidated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unvalidated_df = unvalidated_df[~unvalidated_df.text.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Literal eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"labels\", \"label_list\", \"text_tokens\", \"new_label_list_id\"]:\n",
    "    unvalidated_df[i] = unvalidated_df[i].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unvalidated_df = unvalidated_df.reset_index()\n",
    "unvalidated_df = unvalidated_df.iloc[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unvalidated_df.shape)\n",
    "unvalidated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unvalidated_labelmap = {\n",
    "    \"O\": 0,\n",
    "    \"I-CONTACT\": 1,\n",
    "    \"I-DATE\": 2,\n",
    "    \"I-EVENT\": 3,\n",
    "    \"I-FINANCE\": 4,\n",
    "    \"I-FORM\": 5,\n",
    "    \"I-LOC\": 6,\n",
    "    \"I-MISC\": 7,\n",
    "    \"I-MONEY\": 8,\n",
    "    \"I-ORG\": 9,\n",
    "    \"I-PER\": 10,\n",
    "    \"I-SCHEME\": 11,\n",
    "    \"I-STATE\": 12,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4A. Save CSVs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validated_train.shape)\n",
    "validated_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(validated_test.shape)\n",
    "validated_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(unvalidated_df.shape)\n",
    "unvalidated_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_test.to_csv(\n",
    "    os.path.join(DATA_DIR, \"Feb22-CSV/validated_test.csv\"), index=None\n",
    ")\n",
    "validated_train.to_csv(\n",
    "    os.path.join(DATA_DIR, \"Feb22-CSV/validated_train.csv\"), index=None\n",
    ")\n",
    "unvalidated_df.to_csv(\n",
    "    os.path.join(DATA_DIR, \"Feb22-CSV/unvalidated_train.csv\"), index=None\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4B. Save HFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validated test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_test_df = pd.read_csv(os.path.join(DATA_DIR, \"Feb22-CSV/validated_test.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\n",
    "    \"labels\",\n",
    "    \"labelled_entities\",\n",
    "    \"label_list\",\n",
    "    \"text_tokens\",\n",
    "    \"new_label_list_id\",\n",
    "]:\n",
    "    validated_test_df[i] = validated_test_df[i].apply(lambda x: literal_eval(x))\n",
    "validated_test_df = validated_test_df[[\"text_tokens\", \"new_label_list_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validated_test_hf = Dataset.from_csv(os.path.join(DATA_DIR, 'Jan22-CSV/validated_test.csv'))\n",
    "validated_test_hf = Dataset.from_pandas(validated_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_test_hf.save_to_disk(os.path.join(DATA_DIR, \"Feb22-HF/validated_test\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Validated train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_train_df = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"Feb22-CSV/validated_train.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\n",
    "    \"labels\",\n",
    "    \"labelled_entities\",\n",
    "    \"label_list\",\n",
    "    \"text_tokens\",\n",
    "    \"new_label_list_id\",\n",
    "]:\n",
    "    validated_train_df[i] = validated_train_df[i].apply(lambda x: literal_eval(x))\n",
    "validated_train_df = validated_train_df[[\"text_tokens\", \"new_label_list_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validated_test_hf = Dataset.from_csv(os.path.join(DATA_DIR, 'Jan22-CSV/validated_test.csv'))\n",
    "validated_train_hf = Dataset.from_pandas(validated_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_train_hf.save_to_disk(os.path.join(DATA_DIR, \"Feb22-HF/validated_train\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unvalidated train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unvalidated_train_df = pd.read_csv(\n",
    "    os.path.join(DATA_DIR, \"Feb22-CSV/unvalidated_train.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [\"labels\", \"label_list\", \"text_tokens\", \"new_label_list_id\"]:\n",
    "    unvalidated_train_df[i] = unvalidated_train_df[i].apply(lambda x: literal_eval(x))\n",
    "unvalidated_train_df = unvalidated_train_df[[\"text_tokens\", \"new_label_list_id\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unvalidated_train_hf = Dataset.from_pandas(unvalidated_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unvalidated_train_hf.save_to_disk(os.path.join(DATA_DIR, \"Feb22-HF/unvalidated_train\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unvalidated train sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unvalidated_train_df_sample = unvalidated_train_df.sample(10000, random_state=43)\n",
    "unvalidated_train_df_sample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unvalidated_train_hf_sample = Dataset.from_pandas(unvalidated_train_df_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unvalidated_train_hf_sample.save_to_disk(\n",
    "    os.path.join(DATA_DIR, \"Feb22-HF/unvalidated_train_sample\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4C. Save .json mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, \"Jan22-HF/validated_labelmap.json\"), \"w\") as outfile:\n",
    "    json.dump(validated_labelmap, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, \"Jan22-HF/unvalidated_labelmap.json\"), \"w\") as outfile:\n",
    "    json.dump(unvalidated_labelmap, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(DATA_DIR, \"Feb22-HF/full_labelmap.json\"), \"w\") as outfile:\n",
    "    json.dump(unvalidated_labelmap, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_train_hf.load_from_disk(os.path.join(DATA_DIR, \"Jan22-HF/validated_train\"))\n",
    "validated_test_hf.load_from_disk(os.path.join(DATA_DIR, \"Jan22-HF/validated_test\"))\n",
    "validated_train_hf.load_from_disk(os.path.join(DATA_DIR, \"Jan22-HF/unvalidated_train\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
