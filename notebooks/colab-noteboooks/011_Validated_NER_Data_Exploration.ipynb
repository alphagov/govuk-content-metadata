{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validated NER data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook investigates named entitiy data whose labels were validated by humans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import itertools\n",
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from google.colab import drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are all the folders containing data from the Docanno labelling exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# where we keep data for this project\n",
    "PROJECT_DATA_DIR = (\n",
    "    \"drive/Shareddrives/GOV.UK teams/2020-2021/Data labs/content-metadata-2021/Data\"\n",
    ")\n",
    "\n",
    "# validated data folder\n",
    "DATA_DIR = (\n",
    "    \"drive/Shareddrives/GOV.UK teams/2020-2021/Data labs/govNER (1)/Exported data/\"\n",
    ")\n",
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspecting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's inspect some of this data...\n",
    "\n",
    "Starting with \"import data\". This is the data annotated by GCP NLP API and WordNet Sysnet, which was imported into Docanno for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_fh = os.listdir(DATA_DIR + \"Import data volunteer session 19 06 20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_json(\n",
    "    DATA_DIR + \"Import data volunteer session 19 06 20/\" + annotated_fh[5], lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to show the text that was labelled and what label it was given\n",
    "df[\"entities\"] = df.apply(\n",
    "    lambda x: [(x[\"text\"][pos[0] : pos[1]], pos[2]) for pos in x[\"labels\"]], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annotation quality is low here, as expected.\n",
    "\n",
    "Now let's look at the data that was validated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annotated_fh_val = os.listdir(DATA_DIR + \"Outputs from team sessions\")\n",
    "annotated_fh_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val = df = pd.read_json(\n",
    "    DATA_DIR + \"Outputs from team sessions/\" + annotated_fh_val[0], lines=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column which shows exactly what text is annotated with what label\n",
    "df_val[\"entities\"] = df_val.apply(\n",
    "    lambda x: [(x[\"text\"][pos[0] : pos[1]], pos[2]) for pos in x[\"labels\"]], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initial impression is that the validated data is of much higher quality than the unvalidated data. After inspecting a sample of hundreds of labels from the validated and unvalidated data, a small minority of validated labels appear erroneous (only one of them), whereas a much larger proportion of unvalidated labels appear erroneous (maybe half the labels)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merging validated data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validated data is spread across multiple files and folders. Let's merge everything into one dataset.\n",
    "\n",
    "First, we need the file paths to all of the validated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_data_folders = [\n",
    "    \"Outputs from team sessions\",\n",
    "    \"Output from 2nd March - Content Designers session\",\n",
    "    \"Output from 12th March - Data Scientists session\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_data = [\n",
    "    os.path.join(DATA_DIR, folder, file)\n",
    "    for folder in validated_data_folders\n",
    "    for file in os.listdir(DATA_DIR + folder)\n",
    "]\n",
    "validated_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we concatenate the data from each file into a single data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd = pd.concat(\n",
    "    [pd.read_json(data, lines=True)[[\"text\", \"labels\"]] for data in validated_data]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels aren't always in order of occurrence, so sort them by character position\n",
    "vd.labels = vd.labels.apply(sorted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some labels are repeated, so we remove them here\n",
    "vd.labels = vd.labels.apply(lambda k: list(k for k, _ in itertools.groupby(k)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a column to show exactly what text is assigned to which label\n",
    "vd[\"labelled_entities\"] = vd.apply(\n",
    "    lambda x: [(x[\"text\"][pos[0] : pos[1]], pos[2]) for pos in x[\"labels\"]], axis=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def charPositionLabelsToTokenMapping(labels, text, convention=\"IOB\"):\n",
    "    \"\"\"\n",
    "    Returns a list of labels, mapping to each token in a given text.\n",
    "    This is specific to the situation in which only named entities are labelled, and those labels are not mapped\n",
    "    directly to tokens, but are mapped to character positions.\n",
    "\n",
    "      Parameters:\n",
    "        labels (list of lists): contains character positions of named entities assigned to a given label, in a given text, e.g. [[10, 38, FINANCE], [46, 54, DATE]]\n",
    "        text (string): the string which has been labelled\n",
    "        convention (string): tagging format to be used. Inside-outside-beginning (IOB) as default.\n",
    "\n",
    "      Returns:\n",
    "        label_list (list): list of labels mapping to each token in text\n",
    "\n",
    "    \"\"\"\n",
    "    # flatten labels into a list of character positions\n",
    "    positions = [index for label in labels for index in label[:2]]\n",
    "\n",
    "    # append None and 0 to handle edge cases\n",
    "    positions.append(None)\n",
    "    prev_positions = [0] + positions\n",
    "\n",
    "    # maintain a list of sections of text which belong to the same label\n",
    "    sections = []\n",
    "\n",
    "    # identify sections of text which belong to the same label\n",
    "    for begin, end in zip(prev_positions, positions):\n",
    "        sections.append(text[begin:end])\n",
    "\n",
    "    # remove empty strings and strip spaces left over\n",
    "    sections = [section.strip() for section in sections if section.strip()]\n",
    "\n",
    "    # create a dict of what text corresponds to named entities, and what\n",
    "    # named entity that text has been labelled as\n",
    "    named_entities = {text[i:j]: f\"I-{label}\" for i, j, label in labels}\n",
    "\n",
    "    # group sections of tokens together with their label\n",
    "    label_token_list = [\n",
    "        (section.split(), named_entities[section])\n",
    "        if section in named_entities\n",
    "        else (section.split(), \"O\")\n",
    "        for section in sections\n",
    "    ]\n",
    "\n",
    "    # if convention == 'IOB':\n",
    "    #   # if we have a multi-word entity, make the first label prefixed with 'B-' instead of 'I-'\n",
    "    #   new_l = []\n",
    "    #   for x in label_token_list:\n",
    "    #     if x[1] != 'O' and len(x[0]) > 1:\n",
    "    #       new_l.append((x[0][0],x[1].replace('I-','B-')))\n",
    "    #       new_l.append((x[0][1:],x[1]))\n",
    "    #     else:\n",
    "    #       new_l.append(x)\n",
    "    #   label_token_list = new_l\n",
    "\n",
    "    # directly map each label to a token\n",
    "    label_list = [\n",
    "        label_token[-1] for label_token in label_token_list for _ in label_token[0]\n",
    "    ]\n",
    "    token_list = [token for label_token in label_token_list for token in label_token[0]]\n",
    "\n",
    "    return (label_list, token_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add columns for label lists and the tokens each label maps to\n",
    "vd[[\"label_list\", \"text_tokens\"]] = vd.apply(\n",
    "    lambda x: charPositionLabelsToTokenMapping(x.labels, x.text),\n",
    "    axis=1,\n",
    "    result_type=\"expand\",\n",
    ")\n",
    "vd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd.to_csv(os.path.join(PROJECT_DATA_DIR, \"govuk-labelled-data-ner-validated.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Label counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value counts of labels for each entity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd.labelled_entities.apply(lambda x: [label[1] for label in x]).explode().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value counts of labels for each token."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd.label_list.explode().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MONEY and SCHEME are not present in the validated data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problems with data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Was any data duplicated? In our context, this means to validate the same text more than once."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd[~vd.text.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yes, previously we had 7129 rows of data. After removing rows containing duplicated text, this has decreased by 1287 to 5905 rows. This means 5905 unique sentences were validated, and many were validated multiple times.\n",
    "\n",
    "Let's examine the differences in labelling between repeats of validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd[vd.text.duplicated(keep=False)][[\"text\", \"labelled_entities\"]].sort_values(\"text\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unvalidated data conflates times with money. How are times handled in the validated data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd[vd.text.str.contains(\"pm \", case=False)][[\"text\", \"labelled_entities\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now times are assigned the DATE label instead of MONEY. Although this isn't done with 100% consistency, as some times are not assigned to a named entity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where has the MONEY label gone? Let's check if it was ever used by the Google NLP API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unvalidated_data_folders = [\n",
    "    \"Import data for team session on 03 02 2020\",\n",
    "    \"Import data for data science team 12 03 20\",\n",
    "    \"Import data volunteer session 19 06 20\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unvalidated_data = [\n",
    "    os.path.join(DATA_DIR, folder, file)\n",
    "    for folder in unvalidated_data_folders\n",
    "    for file in os.listdir(DATA_DIR + folder)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uvd = pd.concat(\n",
    "    [pd.read_json(data, lines=True)[[\"text\", \"labels\"]] for data in unvalidated_data]\n",
    ")\n",
    "# add a column to show exactly what text is assigned to which label\n",
    "uvd[\"labelled_entities\"] = uvd.apply(\n",
    "    lambda x: [(x[\"text\"][pos[0] : pos[1]], pos[2]) for pos in x[\"labels\"]], axis=1\n",
    ")\n",
    "# add columns for label lists and the tokens each label maps to\n",
    "uvd[[\"label_list\", \"text_tokens\"]] = uvd.apply(\n",
    "    lambda x: charPositionLabelsToTokenMapping(x.labels, x.text),\n",
    "    axis=1,\n",
    "    result_type=\"expand\",\n",
    ")\n",
    "uvd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I note here that there are 9765 rows of unvalidated data, compared to 7129 rows of validated data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uvd.labelled_entities.apply(\n",
    "    lambda x: [label[1] for label in x]\n",
    ").explode().value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are only 21 entities assigned the MONEY label. Lets inspect the corresponding text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uvd[uvd.label_list.apply(lambda x: \"I-MONEY\" in x)][[\"text\", \"labelled_entities\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspecting this output, MONEY is only tagged to times. Hence, this will have been corrected. But does the text actually mention money? Let's look for text containing currency units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vd[vd.text.str.contains(\"\\\\£|\\\\€|\\\\$\")][[\"text\", \"labelled_entities\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes money is tagged to FINANCE, sometimes it is not tagged to anything."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about entities tagged to SCHEME? We don't have any of those in the validated data, either."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uvd[uvd.label_list.apply(lambda x: \"I-SCHEME\" in x)][[\"text\", \"labelled_entities\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The word 'scheme' is tagged as SCHEME. Understandably, the word 'scheme' isn't informative of what schemes are mentioned on a page. However, in some cases, looking at the text preceding the word 'scheme', an actual scheme is mentioned. After human validation, the SCHEME tags were removed, instead of being extended backwards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
