{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "54c357d4",
   "metadata": {},
   "source": [
    "# HuggingFace Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71a5f73a",
   "metadata": {},
   "source": [
    "This is a notebook to prepare the labelled token dataset for HuggingFace."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22046350",
   "metadata": {},
   "source": [
    "## 1. Installs and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70dd1d91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install datasets\n",
    "# !pip install transformers\n",
    "# !pip install s3fs\n",
    "# !pip install boto3\n",
    "# !pip install sagemaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d50f64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from ast import literal_eval\n",
    "\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import sagemaker\n",
    "import transformers\n",
    "from datasets import Dataset, load_dataset\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21239bc3",
   "metadata": {},
   "source": [
    "## 2. Permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ffd530",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"COLAB\"  # [\"AWS\", \"COLAB\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc54bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if system == \"AWS\":\n",
    "    fs = s3fs.S3FileSystem()\n",
    "    s3_bucket = \"govuk-data-infrastructure-integration\"\n",
    "    DATA_DIR = f\"s3://{s3_bucket}/model-data/govner-data\"\n",
    "    for f in fs.ls(DATA_DIR):\n",
    "        print(f)\n",
    "    # Manage interactions with the Amazon SageMaker APIs and any other AWS services needed.\n",
    "    # sagemaker session bucket -> used for uploading data, models and logs\n",
    "    # sagemaker will automatically create this bucket if it not exists\n",
    "    sess = sagemaker.Session()\n",
    "    sagemaker_session_bucket = s3_bucket\n",
    "    if sagemaker_session_bucket is None and sess is not None:\n",
    "        # set to default bucket if a bucket name is not given\n",
    "        sagemaker_session_bucket = sess.default_bucket()\n",
    "\n",
    "    role = sagemaker.get_execution_role()\n",
    "    sess = sagemaker.Session(default_bucket=sagemaker_session_bucket)\n",
    "\n",
    "    print(f\"sagemaker role arn: {role}\")\n",
    "    print(f\"sagemaker bucket: {sess.default_bucket()}\")\n",
    "    print(f\"sagemaker session region: {sess.boto_region_name}\")\n",
    "elif system == \"COLAB\":\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    # DATA_DIR = os.path.join(\"/content/gdrive/My Drive\", \"NER/Data\")\n",
    "    DATA_DIR = os.path.join(\n",
    "        \"/content/gdrive/Shareddrives/\",\n",
    "        \"GOV.UK teams/2020-2021/Data labs/content-metadata-2021/Data\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UNS04nievzrX",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa278f",
   "metadata": {},
   "source": [
    "## 3. Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bba0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s3 key prefix for the data\n",
    "\n",
    "dataset1_name = \"line_by_line_NER_data_sampled_12062020_more_ents.csv\"\n",
    "dataset2_name = \"line_by_line_NER_data_sampled_09062020_more_ents.csv\"\n",
    "\n",
    "dataset1_path = f\"{DATA_DIR}/{dataset1_name}\"\n",
    "dataset2_path = f\"{DATA_DIR}/{dataset2_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a696b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1 = pd.read_csv(dataset1_path, sep=\"\\t\", low_memory=False)\n",
    "dataset2 = pd.read_csv(dataset2_path, sep=\"\\t\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b57348f",
   "metadata": {},
   "source": [
    "## 4. Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e669a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"dataset1 shape: {dataset1.shape}\")\n",
    "print(f\"dataset2 shape: {dataset2.shape}\")\n",
    "\n",
    "print(\"total rows: {}\".format(dataset1.shape[0] + dataset2.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6219b048",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "yLqYHNrYz-Z5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GkuS_ZR4q6Gd",
   "metadata": {},
   "source": [
    "Investigate some sapmples..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Xas5m7BRq4B-",
   "metadata": {},
   "outputs": [],
   "source": [
    "row = 205652\n",
    "\n",
    "text = dataset1.loc[row][\"text\"]\n",
    "labels = dataset1.loc[row][\"labels\"]\n",
    "print(text)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "erlDvHsHrF8k",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, char in enumerate(text):\n",
    "    print(idx, char)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bIWtNUJy8DhU",
   "metadata": {},
   "source": [
    "Check for duplication..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "NMnijwzd7gsi",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df = pd.merge(dataset1, dataset2, how=\"outer\", indicator=\"Exist\")\n",
    "\n",
    "diff_df = diff_df.loc[diff_df[\"Exist\"] != \"both\"]\n",
    "print(diff_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1nq4o3eW7mDB",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31e36a9",
   "metadata": {},
   "source": [
    "## 5. Concatenation\n",
    "\n",
    "We will concatenate the DaataFrames. They are likely separate for storage/memory reasons. We will combine and shuffle them anyway. We will also add a flag to show what dataset they were originally from too, for later reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0134c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1[\"original_file\"] = \"line_by_line_NER_data_sampled_12062020_more_ents.csv\"\n",
    "dataset2[\"original_file\"] = \"line_by_line_NER_data_sampled_09062020_more_ents.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be4ca73",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset1.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec7dbd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset2.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a49bfa",
   "metadata": {},
   "source": [
    "Combine into one dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc15dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "frames = [dataset1, dataset2]\n",
    "concat = pd.concat(frames)\n",
    "print(concat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b60c48",
   "metadata": {},
   "source": [
    "Shuffle dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0962882f",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df = concat.sample(frac=1).reset_index(drop=True)\n",
    "print(shuffled_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb292386",
   "metadata": {},
   "source": [
    "Convert string list columns to list type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1080ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df[\"text_token\"] = shuffled_df[\"text_token\"].apply(lambda x: literal_eval(x))\n",
    "shuffled_df[\"labels\"] = shuffled_df[\"labels\"].apply(lambda x: literal_eval(x))\n",
    "shuffled_df[\"label_list\"] = shuffled_df[\"label_list\"].apply(lambda x: literal_eval(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dWLp3qu1GuAn",
   "metadata": {},
   "source": [
    "Save to CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "KXfNr98dGtKm",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_name = \"line_by_line_NER_data_combined.csv\"\n",
    "combined_path = f\"{DATA_DIR}/{combined_name}\"\n",
    "combined_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rlHwAk8MHIOR",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df.to_csv(combined_path, sep=\"\\t\", index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa36b13",
   "metadata": {},
   "source": [
    "## 6. Label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "303f65cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map1_name = \"label_map_12062020_more_ents.json\"\n",
    "label_map2_name = \"label_map_09062020_more_ents.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7527863",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map1_path = f\"{DATA_DIR}/{label_map1_name}\"\n",
    "label_map2_path = f\"{DATA_DIR}/{label_map2_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f484ea1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if system == \"COLAB\":\n",
    "    with open(label_map1_path, \"rb\") as f:\n",
    "        label_name_map = json.load(f)\n",
    "    print(label_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca7397c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if system == \"COLAB\":\n",
    "    with open(label_map2_path, \"rb\") as f:\n",
    "        label_name_map = json.load(f)\n",
    "    print(label_name_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f40f5076",
   "metadata": {},
   "source": [
    "Alter label map.\n",
    "\n",
    "Why:\n",
    "* We dont need a label for 'PAD' that will be added later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286e414",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_map = {\n",
    "    \"O\": 0,\n",
    "    \"CONTACT\": 1,\n",
    "    \"DATE\": 2,\n",
    "    \"EVENT\": 3,\n",
    "    \"FINANCE\": 4,\n",
    "    \"FORM\": 5,\n",
    "    \"LOCATION\": 6,\n",
    "    \"MISC\": 7,\n",
    "    \"MONEY\": 8,\n",
    "    \"ORGANIZATION\": 9,\n",
    "    \"PERSON\": 10,\n",
    "    \"SCHEME\": 11,\n",
    "    \"STATE\": 12,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MqzeLdmL-tHq",
   "metadata": {},
   "source": [
    "Save new label map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "x9MAXeoJ-9lJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_label_map_name = \"new_label_map.json\"\n",
    "new_label_map_path = f\"{DATA_DIR}/{new_label_map_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "F-nwJl5I-ba7",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(new_label_map_path, \"w\") as fp:\n",
    "    json.dump(new_label_map, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150cc8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e86e92",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = shuffled_df[\"label_list\"][0]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "170d2140",
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_list_id(labellist, dictionary):\n",
    "    return [dictionary[x] for x in labellist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b94b427",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list_id(labellist=test, dictionary=new_label_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0def9f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df[\"new_label_list_id\"] = shuffled_df[\"label_list\"].apply(\n",
    "    lambda x: label_list_id(x, new_label_map)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab18e787",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "N1DHojWOryFp",
   "metadata": {},
   "source": [
    "## 8. Save DataFrame to gdrive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ia0KUI5isOQH",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_name = \"govuk-labelled-data-ner.csv\"\n",
    "\n",
    "save_df_path = f\"{DATA_DIR}/{save_df_name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HQ3EbQazsgDO",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_df_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "UrVFAyF0sH3n",
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_df.to_csv(save_df_path, index=None)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
