{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cecaa901",
   "metadata": {},
   "source": [
    "# Existing Data Audit\n",
    "\n",
    "The purpose of this notebook is to conduct an audit of the data currently on file from the previous iteration of the govNER project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418f03e3",
   "metadata": {},
   "source": [
    "## 1. Installs and Permissions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ce2e34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install seqeval\n",
    "# !pip install transformers\n",
    "# !pip install torch==1.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b087a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from ast import literal_eval\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "from datetime import date, datetime\n",
    "\n",
    "import boto\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import torch\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from seqeval.metrics import accuracy_score, performance_measure\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import notebook, tqdm\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertForTokenClassification,\n",
    "    BertModel,\n",
    "    BertTokenizerFast,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ffecd0",
   "metadata": {},
   "source": [
    "What's your GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2caf9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e636876a",
   "metadata": {},
   "source": [
    "Define seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb5a7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3fa9d76",
   "metadata": {},
   "source": [
    "Load GOV.UK NER data\n",
    "\n",
    "Paths and filenames..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccd8361",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"AWS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592f6a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "if system == \"AWS\":\n",
    "    fs = s3fs.S3FileSystem()\n",
    "    bucket = \"govuk-data-infrastructure-integration\"\n",
    "    DATA_DIR = f\"s3://{bucket}/model-data/govner-data\"\n",
    "    print(fs.ls(DATA_DIR))\n",
    "elif system == \"COLAB\":\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    DATA_DIR = os.path.join(\n",
    "        \"/content/gdrive/My Drive\", \"transformer_fun/govner/roberta\"\n",
    "    )\n",
    "elif system == \"LOCAL\":\n",
    "    DATA_DIR = os.getenv(\"DATA_DIR\")\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe868e69",
   "metadata": {},
   "source": [
    "## 2. Load the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c04e23d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fs.ls(DATA_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6d4bf8c",
   "metadata": {},
   "source": [
    "Read the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7423909",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_data_file = os.path.join(\n",
    "    DATA_DIR, \"line_by_line_NER_data_sampled_12062020_more_ents.csv\"\n",
    ")\n",
    "label_map_file = os.path.join(DATA_DIR, \"label_map_12062020_more_ents.json\")\n",
    "ner_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f50840a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ner_data_file, sep=\"\\t\", low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc820b8d",
   "metadata": {},
   "source": [
    "## 3. Inspect the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f8578c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53bb1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d78bfac5",
   "metadata": {},
   "source": [
    "To inspect:\n",
    "\n",
    "1. What is the 'updated' column?\n",
    "    \n",
    "    _No evidence for anything useful._\n",
    "    \n",
    "    \n",
    "2. What is the 'original_labels' column?\n",
    "\n",
    "    _It looks like 'original_labels' is the column indicating what they were orgiginally labelled as, perhaps before they had been corrected._\n",
    "    \n",
    "\n",
    "3. What is the 'sampled' column?\n",
    "\n",
    "    _Doesn't look like too much in it. Possibly to indicate what is being sampled when chosing a smaller dataframe size. Those with True sample flags, don't appear to have any 'Sentence: XXX' values for base_path._\n",
    "\n",
    "\n",
    "4. What is the 'base path' column?\n",
    "\n",
    "    _The url path from where the sentence was taken. There are 4,177 examples of base paths with 'Sentence: XXX', These look like random sentences taken from elsewhere._"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3283b424",
   "metadata": {},
   "source": [
    "##### 1. What is the updated column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1127b844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"updated\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af05b720",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"updated\"] == True].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f393741b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"updated\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7572c2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"updated\"] != True].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4e761e",
   "metadata": {},
   "source": [
    "Doesn't seem to be much different.\n",
    "\n",
    "##### 2. What is the original_labels column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae045e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"original_labels\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1809ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"original_labels\"].notna()].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb57c154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"original_labels\"].isna()].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52c53ea9",
   "metadata": {},
   "source": [
    "It looks like 'original_labels' is the column indicating what they were orgiginally labelled as, perhaps before they had been corrected."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c3f227",
   "metadata": {},
   "source": [
    "##### 3.What is the 'sampled' column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16876b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sampled\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2fd639",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"sampled\"] == True].sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bd4e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"sampled\"] == False].sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c822c0e2",
   "metadata": {},
   "source": [
    "Doesn't look like too much in it. Possibly to indicate what is being sampled when chosing a smaller dataframe size.\n",
    "\n",
    "Those with True sample flags, don't appear to have any 'Sentence: XXX' values for base_path."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc184524",
   "metadata": {},
   "source": [
    "##### 4. What is the 'base path' column?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c625188e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"base_path\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60f1b492",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sentence\"] = np.where(df[\"base_path\"].str.startswith(\"Sentence:\"), True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbecbe96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Sentence\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dac7e417",
   "metadata": {},
   "source": [
    "There are 4,177 examples of sentences. These look like random sentences taken from elsewhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2554e57e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Sentence\"] == True].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea334df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"Sentence\"] == False].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93858ce",
   "metadata": {},
   "source": [
    "## 4. Inspect the Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8de434d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if system == \"AWS\":\n",
    "    with fs.open(label_map_file, \"rb\") as f:\n",
    "        label_name_map = json.load(f)\n",
    "    print(label_name_map)\n",
    "else:\n",
    "    with open(label_map_file, \"r\") as f:\n",
    "        label_name_map = json.load(f)\n",
    "    print(label_name_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea4b77f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_list = df[\"label_list\"]\n",
    "print(len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3fa13f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "label_list = list(label_list)\n",
    "print(len(label_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89978655",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_lists = [literal_eval(i) for i in label_list]\n",
    "print(len(list_of_lists))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeccf815",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_list = [item for sublist in list_of_lists for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550cb5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(flat_list))\n",
    "flat_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a598da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c12bb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_counts = Counter(flat_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724e60a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "entity_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fde88fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_c_df = pd.DataFrame.from_dict(entity_counts, orient=\"index\")\n",
    "e_c_df.columns = [\"entity_count\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b51aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_c_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84266e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "entities = e_c_df.index\n",
    "counts = e_c_df[\"entity_count\"]\n",
    "ax.bar(entities, counts)\n",
    "plt.title(\"Labelled Entity Counts\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Entity Type\")\n",
    "ax.set_yticks(np.arange(0, 5000000, 500000))\n",
    "ax.ticklabel_format(axis=\"y\", style=\"plain\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32373acd",
   "metadata": {},
   "source": [
    "Without 'O'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30bcf3db",
   "metadata": {},
   "outputs": [],
   "source": [
    "e_c_df_no_o = e_c_df.drop(\"O\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf76e074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_axes([0, 0, 1, 1])\n",
    "entities = e_c_df_no_o.index\n",
    "counts = e_c_df_no_o[\"entity_count\"]\n",
    "ax.bar(entities, counts)\n",
    "plt.title(\"Labelled Entity Counts\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.xlabel(\"Entity Type\")\n",
    "# ax.set_yticks(np.arange(0, 5000000, 500000))\n",
    "ax.ticklabel_format(axis=\"y\", style=\"plain\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5204f6ea",
   "metadata": {},
   "source": [
    "## Individual Investigation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c79aa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "pd.set_option(\"max_rows\", 100)\n",
    "pd.set_option(\"max_columns\", 100)\n",
    "\n",
    "df[\"text_token\"] = df[\"text_token\"].apply(literal_eval)\n",
    "df[\"label_list\"] = df[\"label_list\"].apply(literal_eval)\n",
    "\n",
    "df.sample(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e85f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text_token_len\"] = df[\"text_token\"].apply(lambda x: len(x))\n",
    "df[\"label_list_len\"] = df[\"label_list\"].apply(lambda x: len(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d189b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb09284",
   "metadata": {},
   "source": [
    "Map 'label_list' column to numeric representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e04e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_name_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be399aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"label_list_map\"] = df[\"label_list\"].apply(\n",
    "    lambda x: list(map(label_name_map.get, x))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66dce6e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af82be90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
