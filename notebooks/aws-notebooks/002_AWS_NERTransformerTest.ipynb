{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6287a394",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install seqeval\n",
    "#!pip install transformers\n",
    "#!pip install torch==1.5.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d66c12c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import re\n",
    "from ast import literal_eval\n",
    "from collections import Counter, OrderedDict, defaultdict\n",
    "from datetime import date, datetime\n",
    "\n",
    "import boto\n",
    "import boto3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import s3fs\n",
    "import torch\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from seqeval.metrics import accuracy_score, performance_measure\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import notebook, tqdm\n",
    "from transformers import (\n",
    "    AdamW,\n",
    "    BertConfig,\n",
    "    BertForTokenClassification,\n",
    "    BertModel,\n",
    "    BertTokenizerFast,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e61a893",
   "metadata": {},
   "source": [
    "What's your GPU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de29d96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "055997e4",
   "metadata": {},
   "source": [
    "Set up transformer classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9de20f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_cls = BertConfig\n",
    "token_class_model_cls = BertForTokenClassification\n",
    "tokenizer_cls = BertTokenizerFast"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cd83ba",
   "metadata": {},
   "source": [
    "Define seeds for reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15320823",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5802b520",
   "metadata": {},
   "source": [
    "Load GOV.UK NER data\n",
    "\n",
    "Paths and filenames..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a51942",
   "metadata": {},
   "outputs": [],
   "source": [
    "system = \"AWS\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f7fa970",
   "metadata": {},
   "outputs": [],
   "source": [
    "if system == \"AWS\":\n",
    "    fs = s3fs.S3FileSystem()\n",
    "    bucket = \"govuk-data-infrastructure-integration\"\n",
    "    DATA_DIR = f\"s3://{bucket}/model-data/govner-data\"\n",
    "    print(fs.ls(DATA_DIR))\n",
    "elif system == \"COLAB\":\n",
    "    from google.colab import drive\n",
    "\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    DATA_DIR = os.path.join(\n",
    "        \"/content/gdrive/My Drive\", \"transformer_fun/govner/roberta\"\n",
    "    )\n",
    "elif system == \"LOCAL\":\n",
    "    DATA_DIR = os.getenv(\"DATA_DIR\")\n",
    "DATA_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56ac3b4",
   "metadata": {},
   "source": [
    "Read the data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd9ba782",
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_data_file = os.path.join(\n",
    "    DATA_DIR, \"line_by_line_NER_data_sampled_12062020_more_ents.csv\"\n",
    ")\n",
    "label_map_file = os.path.join(DATA_DIR, \"label_map_12062020_more_ents.json\")\n",
    "ner_data_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9a431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(ner_data_file, sep=\"\\t\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76216efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "f\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954cb62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if system == \"AWS\":\n",
    "    with fs.open(label_map_file, \"rb\") as f:\n",
    "        label_name_map = json.load(f)\n",
    "    print(label_name_map)\n",
    "else:\n",
    "    with open(label_map_file, \"r\") as f:\n",
    "        label_name_map = json.load(f)\n",
    "    print(label_name_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b60423b9",
   "metadata": {},
   "source": [
    "literal_eval for list values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a416e8d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in [\"text_token\", \"label_list\"]:\n",
    "    print(col)\n",
    "    df[col] = df[col].progress_map(literal_eval)\n",
    "\n",
    "label_map = {v: k for k, v in label_name_map.items()}\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ad81e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df[df.text_token.str.len() != df.label_list.str.len()].shape)\n",
    "print(df[df.text.duplicated()].shape)\n",
    "print(df.base_path.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286c9efd",
   "metadata": {},
   "source": [
    "Subsample, if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b3de91",
   "metadata": {},
   "outputs": [],
   "source": [
    "frac = 0.9\n",
    "int(df.shape[0] * frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834cdaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sample(frac=frac, random_state=RANDOM_SEED)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3a88f45",
   "metadata": {},
   "source": [
    "#### Create torch dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab636a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NERDataset(Dataset):\n",
    "    def __init__(self, sentences, labels, tokenizer, label_map, max_len=256):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.label_map = label_map\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def _tokenize_and_realign_labels(self, sent, labels):\n",
    "        new_labels = []\n",
    "        tokenized = []\n",
    "        for i, (tok, label) in enumerate(zip(sent, labels)):\n",
    "            for t in self.tokenizer.encode([tok], add_special_tokens=False):\n",
    "                new_labels.append(label)\n",
    "                tokenized.append(t)\n",
    "        new_labels = [\"O\"] + new_labels[: self.max_len - 2] + [\"O\"]\n",
    "        tokenized = (\n",
    "            [self.tokenizer.cls_token_id]\n",
    "            + tokenized[: self.max_len - 2]\n",
    "            + [self.tokenizer.sep_token_id]\n",
    "        )\n",
    "        assert len(tokenized) == len(new_labels)\n",
    "        return tokenized, new_labels\n",
    "\n",
    "    def _pad(self, seq):\n",
    "        return seq + [0] * (self.max_len - len(seq))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        sentence_i = self.sentences[i]\n",
    "        label_i = self.labels[i]\n",
    "\n",
    "        assert len(sentence_i) == len(label_i)\n",
    "\n",
    "        input_ids, labels = self._tokenize_and_realign_labels(sentence_i, label_i)\n",
    "        attention_mask = [1] * len(input_ids)\n",
    "        label_num_i = [self.label_map[l] for l in labels]\n",
    "        assert len(label_num_i) == len(input_ids) == len(attention_mask)\n",
    "\n",
    "        return {\n",
    "            \"sentence\": sentence_i,\n",
    "            \"input_ids\": torch.tensor(self._pad(input_ids)),\n",
    "            \"attention_mask\": torch.tensor(self._pad(attention_mask)),\n",
    "            \"text\": \" \".join(self.sentences[i]),\n",
    "            \"labels\": torch.tensor(self._pad(label_num_i), dtype=torch.long),\n",
    "        }\n",
    "\n",
    "\n",
    "def create_data_loader(\n",
    "    df, text_column, target_column, tokenizer, label_map, max_len, batch_size\n",
    "):\n",
    "    ds = NERDataset(\n",
    "        sentences=df[text_column].to_numpy(),\n",
    "        labels=df[target_column].to_numpy(),\n",
    "        tokenizer=tokenizer,\n",
    "        label_map=label_map,\n",
    "        max_len=max_len,\n",
    "    )\n",
    "\n",
    "    return DataLoader(ds, batch_size=batch_size, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b0a9e20",
   "metadata": {},
   "source": [
    "#### Define metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee5bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entities(llist):\n",
    "    prev_tag = \"\"\n",
    "    indices = []\n",
    "    for i, ent in enumerate(llist):\n",
    "        if ent != prev_tag:\n",
    "            indices.append([ent, i, i])\n",
    "        else:\n",
    "            indices[-1][2] = i\n",
    "        prev_tag = ent\n",
    "    return [tuple(i) for i in indices if i[0] != \"O\"]\n",
    "\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    true_entities = set(get_entities(y_true))\n",
    "    pred_entities = set(get_entities(y_pred))\n",
    "\n",
    "    # intersection of predicted and true indexed named\n",
    "    # entities\n",
    "    nb_correct = len(true_entities & pred_entities)\n",
    "    nb_pred = len(pred_entities)\n",
    "    nb_true = len(true_entities)\n",
    "\n",
    "    p = nb_correct / nb_pred if nb_pred > 0 else 0\n",
    "    r = nb_correct / nb_true if nb_true > 0 else 0\n",
    "\n",
    "    return 2 * p * r / (p + r) if p + r > 0 else 0\n",
    "\n",
    "\n",
    "def precision_score(y_true, y_pred):\n",
    "    true_entities = set(get_entities(y_true))\n",
    "    pred_entities = set(get_entities(y_pred))\n",
    "\n",
    "    nb_correct = len(true_entities & pred_entities)\n",
    "    nb_pred = len(pred_entities)\n",
    "\n",
    "    return nb_correct / nb_pred if nb_pred > 0 else 0\n",
    "\n",
    "\n",
    "def recall_score(y_true, y_pred):\n",
    "    true_entities = set(get_entities(y_true))\n",
    "    pred_entities = set(get_entities(y_pred))\n",
    "\n",
    "    nb_correct = len(true_entities & pred_entities)\n",
    "    nb_true = len(true_entities)\n",
    "\n",
    "    return nb_correct / nb_true if nb_true > 0 else 0\n",
    "\n",
    "\n",
    "def classification_report(y_true, y_pred, digits=2):\n",
    "    true_entities = set(get_entities(y_true))\n",
    "    pred_entities = set(get_entities(y_pred))\n",
    "\n",
    "    name_width = 0\n",
    "    d1 = defaultdict(set)\n",
    "    d2 = defaultdict(set)\n",
    "    for e in true_entities:\n",
    "        d1[e[0]].add((e[1], e[2]))\n",
    "        name_width = max(name_width, len(e[0]))\n",
    "    for e in pred_entities:\n",
    "        d2[e[0]].add((e[1], e[2]))\n",
    "\n",
    "    last_line_heading = \"macro avg\"\n",
    "    width = max(name_width, len(last_line_heading), digits)\n",
    "\n",
    "    headers = [\"precision\", \"recall\", \"f1-score\", \"support\"]\n",
    "    head_fmt = \"{:>{width}s} \" + \" {:>9}\" * len(headers)\n",
    "    report = head_fmt.format(\"\", *headers, width=width)\n",
    "    report += \"\\n\\n\"\n",
    "\n",
    "    row_fmt = \"{:>{width}s} \" + \" {:>9.{digits}f}\" * 3 + \" {:>9}\\n\"\n",
    "\n",
    "    ps, rs, f1s, s = [], [], [], []\n",
    "    for type_name, true_entities in d1.items():\n",
    "        pred_entities = d2[type_name]\n",
    "        nb_correct = len(true_entities & pred_entities)\n",
    "        nb_pred = len(pred_entities)\n",
    "        nb_true = len(true_entities)\n",
    "\n",
    "        p = nb_correct / nb_pred if nb_pred > 0 else 0\n",
    "        r = nb_correct / nb_true if nb_true > 0 else 0\n",
    "        f1 = 2 * p * r / (p + r) if p + r > 0 else 0\n",
    "\n",
    "        report += row_fmt.format(\n",
    "            *[type_name, p, r, f1, nb_true], width=width, digits=digits\n",
    "        )\n",
    "\n",
    "        ps.append(p)\n",
    "        rs.append(r)\n",
    "        f1s.append(f1)\n",
    "        s.append(nb_true)\n",
    "\n",
    "    report += \"\\n\"\n",
    "\n",
    "    # compute averages\n",
    "    report += row_fmt.format(\n",
    "        \"micro avg\",\n",
    "        precision_score(y_true, y_pred),\n",
    "        recall_score(y_true, y_pred),\n",
    "        f1_score(y_true, y_pred),\n",
    "        np.sum(s),\n",
    "        width=width,\n",
    "        digits=digits,\n",
    "    )\n",
    "    report += row_fmt.format(\n",
    "        last_line_heading,\n",
    "        np.average(ps, weights=s),\n",
    "        np.average(rs, weights=s),\n",
    "        np.average(f1s, weights=s),\n",
    "        np.sum(s),\n",
    "        width=width,\n",
    "        digits=digits,\n",
    "    )\n",
    "\n",
    "    return report\n",
    "\n",
    "\n",
    "y_true = [\"a\", \"a\", \"b\", \"o\", \"o\", \"i\", \"a\"]\n",
    "y_pred = [\"a\", \"a\", \"O\", \"o\"]\n",
    "print(classification_report(y_true, y_pred, digits=4))\n",
    "print(accuracy_score(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "500c338b",
   "metadata": {},
   "source": [
    "#### Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc925be",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model name\n",
    "# 'bert-base-cased' \"roberta-base\"\n",
    "MODEL_NAME = \"bert-base-cased\"\n",
    "MODEL_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2068edd8",
   "metadata": {},
   "source": [
    "#### Define model config\n",
    "\n",
    "hidden_size (int, optional, defaults to 768) – Dimensionality of the encoder layers and the pooler layer.\n",
    "\n",
    "num_hidden_layers (int, optional, defaults to 12) – Number of hidden layers in the Transformer encoder.\n",
    "\n",
    "num_attention_heads (int, optional, defaults to 12) – Number of attention heads for each attention layer in the Transformer encoder.\n",
    "\n",
    "intermediate_size (int, optional, defaults to 3072) – Dimensionality of the “intermediate” (i.e., feed-forward) layer in the Transformer encoder.\n",
    "\n",
    "hidden_act (str or function, optional, defaults to “gelu”) – The non-linear activation function (function or string) in the encoder and pooler. If string, “gelu”, “relu”, “swish” and “gelu_new” are supported.\n",
    "\n",
    "hidden_dropout_prob (float, optional, defaults to 0.1) – The dropout probabilitiy for all fully connected layers in the embeddings, encoder, and pooler.\n",
    "\n",
    "attention_probs_dropout_prob (float, optional, defaults to 0.1) – The dropout ratio for the attention probabilities.\n",
    "\n",
    "max_position_embeddings (int, optional, defaults to 512) – The maximum sequence length that this model might ever be used with. Typically set this to something large just in case (e.g., 512 or 1024 or 2048).\n",
    "\n",
    "initializer_range (float, optional, defaults to 0.02) – The standard deviation of the truncated_normal_initializer for initializing all weight matrices.\n",
    "\n",
    "layer_norm_eps (float, optional, defaults to 1e-12) – The epsilon used by the layer normalization layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62eefa4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = config_cls.from_pretrained(MODEL_NAME, num_labels=len(label_map))\n",
    "model = token_class_model_cls.from_pretrained(MODEL_NAME, config=config)\n",
    "print(list(model.classifier.named_parameters()))\n",
    "print(model.num_parameters())\n",
    "print(model.dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7e73628",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa08379",
   "metadata": {},
   "source": [
    "#### Define a tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd35c740",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tokenizer_cls.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87c85ace",
   "metadata": {},
   "source": [
    "#### Define an optimizer and learning parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aedaa97",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-5\n",
    "eps = 1e-8\n",
    "\n",
    "FULL_FINETUNING = True\n",
    "if FULL_FINETUNING:\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = [\"bias\", \"gamma\", \"beta\"]\n",
    "    optimizer_grouped_parameters = [\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if not any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay_rate\": 0.01,\n",
    "        },\n",
    "        {\n",
    "            \"params\": [\n",
    "                p for n, p in param_optimizer if any(nd in n for nd in no_decay)\n",
    "            ],\n",
    "            \"weight_decay_rate\": 0.0,\n",
    "        },\n",
    "    ]\n",
    "else:\n",
    "    param_optimizer = list(model.classifier.named_parameters())\n",
    "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=lr, eps=eps)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70597d35",
   "metadata": {},
   "source": [
    "#### Data splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2949ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=RANDOM_SEED)\n",
    "\n",
    "df_val, df_test = train_test_split(df_test, test_size=0.5, random_state=RANDOM_SEED)\n",
    "\n",
    "df_train.shape, df_val.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b831957e",
   "metadata": {},
   "source": [
    "#### Define parameters for data input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44bdb25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 24\n",
    "MAX_LEN = 256\n",
    "text_column = \"text_token\"\n",
    "target_column = \"label_list\"\n",
    "\n",
    "train_data_loader = create_data_loader(\n",
    "    df_train, text_column, target_column, tokenizer, label_name_map, MAX_LEN, BATCH_SIZE\n",
    ")\n",
    "val_data_loader = create_data_loader(\n",
    "    df_val, text_column, target_column, tokenizer, label_name_map, MAX_LEN, BATCH_SIZE\n",
    ")\n",
    "test_data_loader = create_data_loader(\n",
    "    df_test, text_column, target_column, tokenizer, label_name_map, MAX_LEN, BATCH_SIZE\n",
    ")\n",
    "\n",
    "len(train_data_loader), len(train_data_loader) * BATCH_SIZE, df_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43a509b",
   "metadata": {},
   "source": [
    "#### Scheduling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fae1e0e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 10\n",
    "max_grad_norm = 1.0\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_data_loader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4f85b6e",
   "metadata": {},
   "source": [
    "#### Define functions for training and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b283f91",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, data_loader, optimizer, device, scheduler):\n",
    "\n",
    "    model = model.train()\n",
    "    train_loss = []\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "\n",
    "    for d in notebook.tqdm(data_loader):\n",
    "        input_ids = d[\"input_ids\"].to(device)\n",
    "        attention_mask = d[\"attention_mask\"].to(device)\n",
    "        labels = d[\"labels\"].to(device)\n",
    "\n",
    "        outputs = model(\n",
    "            input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "        )\n",
    "\n",
    "        loss = outputs[0]\n",
    "        train_loss.append(loss.item())\n",
    "\n",
    "        logits = outputs[1].detach().cpu().numpy()\n",
    "        label_ids = labels.to(\"cpu\").numpy()\n",
    "\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.extend(label_ids)\n",
    "\n",
    "        loss.backward()\n",
    "\n",
    "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "    return true_labels, predictions, np.mean(train_loss)\n",
    "\n",
    "\n",
    "def eval_model(model, data_loader, device):\n",
    "    model = model.eval()\n",
    "    eval_loss = []\n",
    "    predictions = []\n",
    "    true_labels = []\n",
    "    for batch in notebook.tqdm(data_loader):\n",
    "\n",
    "        with torch.no_grad():\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(\n",
    "                input_ids=input_ids, attention_mask=attention_mask, labels=labels\n",
    "            )\n",
    "\n",
    "        loss = outputs[0]\n",
    "        eval_loss.append(loss.item())\n",
    "\n",
    "        logits = outputs[1].detach().cpu().numpy()\n",
    "        label_ids = labels.to(\"cpu\").numpy()\n",
    "\n",
    "        predictions.extend([list(p) for p in np.argmax(logits, axis=2)])\n",
    "        true_labels.extend(label_ids)\n",
    "\n",
    "    return true_labels, predictions, np.mean(eval_loss)\n",
    "\n",
    "\n",
    "def get_stats(predictions_local, true_labels_local, loss, loss_name=\"Train\"):\n",
    "    pred_tags = [\n",
    "        label_map[p_i]\n",
    "        for p, l in zip(predictions_local, true_labels_local)\n",
    "        for p_i, l_i in zip(p, l)\n",
    "        if label_map[l_i] != \"PAD\"\n",
    "    ]\n",
    "    valid_tags = [\n",
    "        label_map[l_i]\n",
    "        for l in true_labels_local\n",
    "        for l_i in l\n",
    "        if label_map[l_i] != \"PAD\"\n",
    "    ]\n",
    "    acc = accuracy_score(valid_tags, pred_tags) * 100\n",
    "    print(f\"{loss_name} loss {loss} accuracy {acc}\\n\")\n",
    "    print(classification_report(valid_tags, pred_tags, digits=4))\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b7746b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_saver(model, filename):\n",
    "    if system == \"AWS\":\n",
    "        with fs.open(filename, \"wb\") as f:\n",
    "            torch.save(model.state_dict(), f)\n",
    "    else:\n",
    "        torch.save(model.state_dict(), filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e6e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d65cf3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "name_for_saving = (\n",
    "    f\"{MODEL_NAME}_{BATCH_SIZE}_{MAX_LEN}_\"\n",
    "    + f\"{df_train.shape[0]}_{df_test.shape[0]}_\"\n",
    "    + f\"{lr}_{eps}_{epochs}\"\n",
    ")\n",
    "name_for_saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbafeb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = defaultdict(list)\n",
    "best_accuracy = 0\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    true_labels, predictions, train_loss = train_epoch(\n",
    "        model, train_data_loader, optimizer, device, scheduler\n",
    "    )\n",
    "    train_acc = get_stats(predictions, true_labels, train_loss, \"Train\")\n",
    "\n",
    "    true_labels, predictions, val_loss = eval_model(model, val_data_loader, device)\n",
    "    val_acc = get_stats(predictions, true_labels, val_loss, \"Val\")\n",
    "\n",
    "    history[\"train_acc\"].append(train_acc)\n",
    "    history[\"train_loss\"].append(train_loss)\n",
    "    history[\"val_acc\"].append(val_acc)\n",
    "    history[\"val_loss\"].append(val_loss)\n",
    "\n",
    "    if val_acc > best_accuracy:\n",
    "        filename = os.path.join(DATA_DIR, f\"{name_for_saving}_model_state.bin\")\n",
    "        model_saver(model, filename)\n",
    "        best_accuracy = val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54156161",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
