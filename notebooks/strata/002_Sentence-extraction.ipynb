{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 002_Sentence-extraction\n",
    "\n",
    "Purpose:\n",
    "Stratified sampling run across gov.uk to get sample of base paths. Now to extract the sentences from these base paths.\n",
    "\n",
    "1. Connect to mongodb container\n",
    "2. Get base paths\n",
    "3. Filter db by base paths\n",
    "4. Extract only text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pprint\n",
    "import random\n",
    "from datetime import datetime\n",
    "from typing import Dict, List\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "\n",
    "#scraping\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from bson import ObjectId, json_util\n",
    "from clumper import Clumper\n",
    "from dotenv import load_dotenv  # pip install python-dotenv\n",
    "from pandas.io.json import json_normalize\n",
    "\n",
    "# make sure a .env file exists in the same directory, with a line like this:\n",
    "# KG_PWD=<insert password here>\n",
    "load_dotenv()\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Connect to mongodb container\n",
    "\n",
    "Get database running locally as per the instructions in this README."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or whatever port it's at\n",
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myclient.list_database_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = myclient[\"content_store\"]\n",
    "mycol = mydb[\"content_items\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first parameter of the find() method is the filter that all returned records must match (we can leave it empty to get all records). With projections, we can select specific fields from the returned documents. The projections are passed in the second argument of the find() method where 1 means True, we want that returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_record = mycol.find_one({\"_id\": \"/30-hours-free-childcare\"}, projection={'details.body.content':1})\n",
    "#find_record = mycol.find_one({\"_id\": \"/30-hours-free-childcare\"}, projection={'details':1})\n",
    "find_record"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Get base paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR_SRC_STRATA = os.environ.get('DIR_SRC_STRATA')\n",
    "\n",
    "base_paths_df = pd.read_csv(os.path.join(DIR_SRC_STRATA, 'data/schemas_stratified_random_sample.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_paths_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A little bit of EDA..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_paths_df['schema_name'].value_counts().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_paths_df['document_type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_paths_df['schema_strata_name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_paths_df['base_path'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_paths_list = list(base_paths_df['base_path'])\n",
    "base_paths_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Filter db by base paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 'details, licence_overview, content' x5\n",
    "* 'details, introductory_paragraph, content' x3\n",
    "* 'details, body, content' *2\n",
    "* 'details, body'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_base_path = random.choice(base_paths_list)\n",
    "print(random_base_path)\n",
    "\n",
    "records = mycol.find({\"_id\": random_base_path})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for record in records:\n",
    "  pprint.pprint(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mongo_data(base_path):\n",
    "    records = mycol.find({\"_id\": base_path}, projection={'details.body.content':1})\n",
    "    for record in records:\n",
    "        record = record\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mongo_to_dataframe(mongo_data):\n",
    "    \"\"\"Get nested JSON lines into a pandas dataframe.\n",
    "    \n",
    "    Sanitize by loading as a regular JSON. Un-nest the data with normalise\n",
    "    then turn into a pandas dataframe.\n",
    "    \"\"\"\n",
    "\n",
    "    sanitized = json.loads(json_util.dumps(mongo_data))\n",
    "    normalized = json_normalize(sanitized)\n",
    "    df = pd.DataFrame(normalized)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "record = get_mongo_data(base_path=base_paths_list[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_to_dataframe(record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_list = []\n",
    "\n",
    "for i in base_paths_list:\n",
    "    record = get_mongo_data(base_path=i)\n",
    "    df = mongo_to_dataframe(record)\n",
    "    df_list.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df = pd.concat(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(master_df.shape[0])\n",
    "print(master_df['details.body'].isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Scrape Govuk Content (using content api)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET_PAGES = base_paths_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_content_api(page_api_url: str) -> requests.models.Response:\n",
    "  \"\"\"\"\"\"\n",
    "  return(requests.get(page_api_url))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_text_parts(api_content_json: requests.models.Response) -> List[dict]:\n",
    "  \"\"\"\n",
    "  Extracts:\n",
    "  - main title\n",
    "  - main body (if any)\n",
    "  - chapter headings (if any)\n",
    "  - chapter sections (if any)\n",
    "  from a gov.uk page, fetched through the api/content.\n",
    "\n",
    "  Strips html/css markdown. \n",
    "\n",
    "  Removes hyperlinks.\n",
    "\n",
    "  Adds the necessary punctuation to preserve paragraph and sentence structure:\n",
    "  - \":\" after a (sub)heading so that the sub(heading) and text are presented together\n",
    "  - \".\" at the end of the last bullet point\n",
    "  - \";\" at the end of a non-final bullet point\n",
    "\n",
    "  Returns a {title: str, sections: list(str), headings: list(str)} dictionary.\n",
    "  \"\"\"\n",
    "\n",
    "  main_title = api_content_json.json()['title']\n",
    "\n",
    "  try:\n",
    "    main_body = BeautifulSoup(api_content_json.json()['details']['body'].replace(\"</h2>\", \":\").replace(\"</h3>\", \":\").replace(\"</h4>\", \":\").replace('</li>\\n</ul>', '.').replace('</li>\\n', ';').replace('\\n', ' '), \n",
    "                                 \"html.parser\").get_text()\n",
    "  except KeyError:\n",
    "    main_body = \"\"\n",
    "  \n",
    "  try: \n",
    "    body_sections = [BeautifulSoup(d['body'].replace(\"</h2>\", \":\").replace(\"</h3>\", \":\").replace(\"</h4>\", \":\").replace('</li>\\n</ul>', '.').replace('</li>\\n', ';').replace('\\n', ' '), \n",
    "                                  \"html.parser\").get_text() for d in api_content_json.json()['details']['parts']]\n",
    "\n",
    "    body_headings = [d['title'] for d in api_content_json.json()['details']['parts']]\n",
    "\n",
    "  except KeyError:\n",
    "    body_sections = []\n",
    "    body_headings = []\n",
    "\n",
    "\n",
    "  return({\"title\": main_title, \"main_text\": main_body, \"sections\": body_sections, \"headings\": body_headings})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_structured_content(list_target_pages) -> Dict[str, dict]:\n",
    "  \"\"\"\n",
    "  Given a list of page paths (format: '/universal-credit'):\n",
    "    - scrape the content of the page using the gov.uk/api/content\n",
    "    - extract the main text components: page title, headings, main body text, section texts.\n",
    "\n",
    "  Returns a dictionary (page_path, dictionary of text components)\n",
    "  \"\"\"\n",
    "\n",
    "  DOMAIN = \"https://www.gov.uk/api/content\"\n",
    "\n",
    "  results_dict = {}\n",
    "\n",
    "  for page in list_target_pages:\n",
    "    api_url = DOMAIN + page\n",
    "    response = get_content_api(api_url)\n",
    "    results_dict[page] = get_text_parts(response)\n",
    "\n",
    "  return(results_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict = get_structured_content(TARGET_PAGES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Using MongoDB again..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myclient = pymongo.MongoClient(\"mongodb://localhost:27017/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(myclient.list_database_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb = myclient[\"content_store\"]\n",
    "mycol = mydb[\"content_items\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blacklisted_content_page = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_columns = \\\n",
    "['_id', \n",
    "                'access_limited', \n",
    "                'analytics_identifier', \n",
    "'content_id',\n",
    "'content_purpose_document_supertype', \n",
    "'content_purpose_subgroup',\n",
    "'content_purpose_supergroup', \n",
    "'created_at', \n",
    "'description', \n",
    "'details',\n",
    "'document_type', \n",
    "'email_document_supertype', \n",
    "'expanded_links',\n",
    "'first_published_at', \n",
    "                'format', \n",
    "'government_document_supertype',\n",
    "                'links', \n",
    "'locale', \n",
    "'navigation_document_supertype', \n",
    "                'need_ids',\n",
    "                'payload_version', \n",
    "'phase', \n",
    "'public_updated_at', \n",
    "'publishing_app',\n",
    "                'publishing_request_id', \n",
    "'publishing_scheduled_at', \n",
    "                'redirects',\n",
    "'rendering_app', \n",
    "                'routes', \n",
    "                'scheduled_publishing_delay_seconds',\n",
    "                'schema_name', \n",
    "'search_user_need_document_supertype', \n",
    "'title',\n",
    "'updated_at', \n",
    "'user_journey_document_supertype' \n",
    "                'withdrawn_notice'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "links_keep = \\\n",
    "[\n",
    "'organisations',\n",
    "'primary_publishing_organisation',\n",
    "'taxons',\n",
    " 'finder',\n",
    " 'available_translations',\n",
    "'mainstream_browse_pages',\n",
    "# 'parent',\n",
    "'part_of_step_navs',\n",
    "'ordered_related_items',\n",
    " 'meets_user_needs',\n",
    "'topics',\n",
    "'ordered_related_items_overrides',\n",
    "'pages_part_of_step_nav',\n",
    "'pages_related_to_step_nav',\n",
    "'related_to_step_navs',\n",
    "'children',\n",
    "'document_collections',\n",
    " 'lead_organisations',\n",
    " 'world_locations',\n",
    " 'worldwide_organisations',\n",
    " 'supporting_organisations',\n",
    " 'worldwide_priorities',\n",
    "'original_primary_publishing_organisation',\n",
    "'documents',\n",
    "'policy_areas',\n",
    "'topical_events',\n",
    " 'suggested_ordered_related_items',\n",
    "'related_policies',\n",
    "'ministers',\n",
    "'people',\n",
    "'roles',\n",
    " 'field_of_operation'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_keys = \\\n",
    "[\n",
    "'analytics_identifier', \n",
    "'api_path', \n",
    "'base_path', \n",
    "'content_id', \n",
    "'description', \n",
    "'document_type', \n",
    "'locale', \n",
    "'schema_name', \n",
    "'title', \n",
    "'withdrawn', \n",
    "'details', \n",
    "'links'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_expanded_links(content_links, row_dict):\n",
    "    for key,value in content_links.items():\n",
    "        if key in links_keep:\n",
    "            row_dict[key] = []\n",
    "            for item in value:\n",
    "                row = {}\n",
    "                for k in keep_keys:\n",
    "                    if k in item.keys():\n",
    "                        row[k] = item[k]\n",
    "                row_dict[key].append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydoc = mycol.find({ \"$and\": [\n",
    "                    { \"document_type\": {\"$not\" : { \"$in\": blacklisted_content_page}}},\n",
    "                    { \"phase\": \"live\"}]})\n",
    "print(\"Started:\",datetime.now().strftime(\"%H:%M:%S\"))\n",
    "rowlist = []\n",
    "for i,item in enumerate(mydoc):\n",
    "    if i < 50000:\n",
    "        row = {key:value for key,value in item.items() if key in keep_columns}\n",
    "#         row['body'] = extract_from_details(item['details'], \"text\")\n",
    "#         row['embedded_links'] = extract_from_details(item['details'], \"links\")\n",
    "        if \"expanded_links\" in item.keys():\n",
    "            handle_expanded_links(item[\"expanded_links\"], row)    \n",
    "        rowlist.append(row)\n",
    "    else:\n",
    "        break\n",
    "    if i % 10000==0:\n",
    "        print(i,datetime.now().strftime(\"%H:%M:%S\"))\n",
    "print(\"Ended:\",datetime.now().strftime(\"%H:%M:%S\"))\n",
    "df = pd.DataFrame(rowlist)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.iloc[1])\n",
    "print('*'*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "cb78078aff4f0fca0b87149217d885ad4dd99935d8eaa10d490c5420d431fcbd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
